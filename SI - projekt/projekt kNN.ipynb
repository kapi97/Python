{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Przetwarzenie danych wejściowych\n",
    "Czyta z pliku \"letter-recognition.data\" dane tych liter, które mają zostać uwzględnione w badaniu. Następnie umieszcza na liście y etykiety klas (litery), a na liście X, wektory cech tychże klas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = [] #lista wektorów reprezentujących litery\n",
    "y = [] #lista etykiet klas (litery)\n",
    "litery = ('P','R','O','S','I','A','C','Z','E','K')\n",
    "\n",
    "with open(\"letter-recognition.data\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if line[0] in litery:\n",
    "            \n",
    "            #odrzua znaki końca linii\n",
    "            line = line.rstrip('\\n')\n",
    "            \n",
    "            #przecinek jest znakiem rozdzielającym wyrazy (wartości)\n",
    "            line = line.split(\",\")\n",
    "            \n",
    "            #pierwszy znak w linii to etykieta klasy - dodaje do y\n",
    "            y.append(line[0])\n",
    "            \n",
    "            #pozostałe znaki w linii to wartości wektora - parsuje na liczbę całkowitą i dodaje do X\n",
    "            X.append([int(v) for v in line[1:len(line)]])\n",
    "\n",
    "#normalizacja cech\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X = mms.fit_transform(X)\n",
    "\n",
    "#standaryzacja cech\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#stdsc = StandardScaler()\n",
    "#X = stdsc.fit_transform(X)\n",
    "\n",
    "#konwersja z listy na macierz (dla wygody)\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Przygotowanie danych\n",
    "Dzieli wczytane dane na dwie części: zbiór uczący i zbiór testowy, gdzie zbiór uczący domyślnie stanowi 80% danych wejściowych, a zbiór testowy 20%.\n",
    "\n",
    "Zwraca tuple (krotkę) zawierającą:\n",
    "- training_samples - zbiór wektorów cech treningowych o rozmiarze train_size X ilosc_cech\n",
    "- test_samples - zbiór wektorów cech testowych o rozmiarze test_size X ilosc_cech\n",
    "- training_classes - zbiór nazw klas (litery) dla zbioru treningowego\n",
    "- test_classes - zbiór nazw klas (litery) dla zbioru testowego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareDataSet(Samples, Classes, ratio=.8, random=True):\n",
    "\n",
    "    #wyznaczenie rozmiarów zbiorów (uczącego i testowego)\n",
    "    train_size = int(ratio * Samples.shape[0])\n",
    "    test_size = Samples.shape[0] - train_size\n",
    "\n",
    "    if random:\n",
    "        #wymieszanie danych - dzięki temu za każdym razem, gdy będzie budowany nowy klasyfikator,\n",
    "        #inna część będzie brana do uczenia, a inna do testów\n",
    "        indices = np.random.permutation(Samples.shape[0])\n",
    "    else:\n",
    "        indices = np.arange(Samples.shape[0])\n",
    "\n",
    "    #tablice wymieszanych indeksów (część do uczenia i część do testów)\n",
    "    training_idx = indices[:train_size]\n",
    "    test_idx = indices[train_size:]\n",
    "\n",
    "    #zbiory wektorów cech (część do uczenia i część do testów)\n",
    "    training_samples, test_samples = Samples[training_idx,:], Samples[test_idx,:]\n",
    "\n",
    "    #zbiory klas (część do uczenia i część do testów)\n",
    "    training_classes, test_classes = Classes[training_idx,], Classes[test_idx,]\n",
    "\n",
    "    return (training_samples, test_samples, training_classes, test_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Uruchomienie eksperymentu\n",
    "Tworzy nowy klasyfikator oparty o metodę minimalno-odległościową kNN i zadane parametry. Następnie 'uczy się' rozpoznawać klasy wykorzystując dane treningowe i przeprowadza test na zbiorze testowym.\n",
    "\n",
    "Zwraca tuple (krotkę) zawierającą:\n",
    "- accurancy - dokładność, z jaką udało się dopasować klasy\n",
    "- verification_time - czas potrzebny na sklasyfikowanie danych\n",
    "\n",
    "Parametry klasyfikatora:\n",
    "- n_neighbours - liczba najbliższych sąsiadów; dowolna liczba naturalna (w granicah rozsądku); domyślnie 5\n",
    "- weights - określenia jakie wagi mają być przypisane do odległości od sąsiada; przyjmuje wartość \"uniform\" (wszystkie odległości mają taką samą wagę) lub \"distance\" (im większa odległość, tym mniejsza waga); domyślnie \"uniform\"\n",
    "- metric - pod uwagę brane są 3 metryki: \"manhattan\", \"euclidean\", \"minkowski\"; domyślnie \"minkowski\"\n",
    "- p - parametr potęgi do metryki \"minkowski\"; domyślnie 2\n",
    "- algorithm - algorytm używany do obliczania odległości najbliższego sąsiada; dostępne są: \"auto\", \"ball_tree\", \"kd_tree\", \"brute\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "def runExperiment(dataSet, n_neighbors, metric, strategy='none', p=3):\n",
    "    \n",
    "    training_samples, test_samples, training_classes, test_classes = dataSet\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    #tworzenie kalsyfikatora\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, weights='uniform', metric=metric, p=p, algorithm='kd_tree') \n",
    "    \n",
    "    #narzucenie strategii decyzyjnej\n",
    "    if strategy.lower() == 'ovo':\n",
    "        classifier = OneVsOneClassifier(knn)\n",
    "    elif strategy.lower() == 'ovr':\n",
    "        classifier = OneVsRestClassifier(knn)\n",
    "    else:\n",
    "        classifier = knn\n",
    "      \n",
    "    #\"uczenie\"\n",
    "    classifier.fit(training_samples, training_classes)\n",
    "\n",
    "    #przeprowadzenie testu\n",
    "    pred_classes = classifier.predict(test_samples)\n",
    "\n",
    "    #obliczenie dokładności\n",
    "    accurancy = round(100*accuracy_score(test_classes, pred_classes),4)\n",
    "\n",
    "    end_time = time.time()\n",
    "    \n",
    "    #obliczenie czasu\n",
    "    verification_time = round(end_time - start_time,4)\n",
    "    \n",
    "    return (accurancy, verification_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test jednostkowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#przygotowanie danych z pełnym zestawem cech\n",
    "dataSet_full = prepareDataSet(X,y, random=False)\n",
    "#print(dataSet_full[0].shape, dataSet_full[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność: 97.96%\n",
      "Czas weryfikacji: 1.25s\n"
     ]
    }
   ],
   "source": [
    "#wykonanie eksperymentu na pełnych danych i wypisanie wyniku\n",
    "result_full = runExperiment(dataSet_full, 3, 'manhattan', 'ovr')\n",
    "\n",
    "print('Dokładność: {:.2f}%'.format(result_full[0]))\n",
    "print('Czas weryfikacji: {:.2f}s'.format(result_full[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Redukcja wymiaru przestrzeni cech (metoda PCA)\n",
    "Celem tego zabiegu jest zmniejszenie ilości cech (rozmiaru wektora). Dzięki temu, klasyfikator ma mniej liczenia, a co za tym idzie, eksperyment wykonuje się szybciej. Jednak zmniejsza się dokładność rozpoznawania klas przez klasyfikator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#funkcja redukująca przestrzeń cech (pełny wymiar = 16)\n",
    "def reduceWithPCA(reduction, Samples):\n",
    "\n",
    "    pca = PCA(n_components=reduction)\n",
    "    pca.fit(Samples)\n",
    "\n",
    "    #print(pca.explained_variance_ratio_)  \n",
    "    #print(pca.explained_variance_)  \n",
    "\n",
    "    reducedX = pca.transform(Samples)\n",
    "    return reducedX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test jednostkowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#przygotowanie danych ze zredukowanym zestawem cech\n",
    "reducedX = reduceWithPCA(14, X)\n",
    "dataSet_reduced = prepareDataSet(reducedX,y, random=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność: 98.29%\n",
      "Czas weryfikacji: 3.53s\n"
     ]
    }
   ],
   "source": [
    "#wykonanie eksperymentu na zredukowanych danych i wypisanie wyniku\n",
    "result_reduced = runExperiment(dataSet_reduced, 3, 'euclidean', 'ovo')\n",
    "\n",
    "print('Dokładność: {:.2f}%'.format(result_reduced[0]))\n",
    "print('Czas weryfikacji: {:.2f}s'.format(result_reduced[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Szukanie optymalnych parametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bardzo nieładna funkcja zwracająca unikalną 'kombinację' wszystkich parametrów\n",
    "def prepareParams(neighbours, metrics):\n",
    "    \n",
    "    strategies = ['OvO', 'OvR']\n",
    "    params = []\n",
    "    \n",
    "    for n in neighbours:\n",
    "        params.append([n, metrics[0], strategies[0]])\n",
    "        params.append([n, metrics[0], strategies[1]])\n",
    "        params.append([n, metrics[1], strategies[0]])\n",
    "        params.append([n, metrics[1], strategies[1]])\n",
    "        params.append([n, metrics[2], strategies[0]])\n",
    "        params.append([n, metrics[2], strategies[1]])\n",
    "    \n",
    "    return params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcja przeprowadza eksperymenty dla każdej kombinacji parametrów\n",
    "#zapisuje dane wynikowe do pliku, zwraca najlepszy rezultat, a także wskazuje, który zestaw parametrów jest prawdopodobnie najlepszy\n",
    "def runOverallExperiment(neighbours, metrics, filename):\n",
    "    \n",
    "    params = prepareParams(neighbours, metrics)\n",
    "    \n",
    "    accurancies, veri_times, optim_values = [],[],[]\n",
    "    \n",
    "    #wpisanie do pliku nagłówków kolumn\n",
    "    with open(filename + '.csv', 'w') as plik:\n",
    "        plik.write('liczba_sasiadow;metryka;strategia;dokladnosc;czas_weryfikacji;wartosc_optimum\\n')\n",
    "        \n",
    "    #wykonanie eksperymentów i uzupełnienie danych\n",
    "    for p in params:\n",
    "        result = runExperiment(dataSet_full, p[0], p[1], p[2])\n",
    "        \n",
    "        #wyliczanie współczynnika optymalności\n",
    "        #liczba przed 'result[1]' to waga czasu. Można zwiększyć, aby czas miał większy wpływ przy określaniu optimum\n",
    "        opt = round((result[0] - .15*result[1])/100,8)\n",
    "        \n",
    "        accurancies.append(result[0])\n",
    "        veri_times.append(result[1])\n",
    "        optim_values.append(opt)\n",
    "        \n",
    "        with open(filename + '.csv', 'a') as plik:\n",
    "            plik.write(str(p[0]) + ';' + p[1] + ';' + p[2] + ';' + str(result[0]).replace('.',',') + ';' + str(result[1]).replace('.',',') + ';' + str(opt).replace('.',',') + '\\n')\n",
    "        \n",
    "    #szukanie najwyższej wartości optimum\n",
    "    opid = optim_values.index(max(optim_values))\n",
    "    founded_optim = params[opid] + [accurancies[opid]] + [veri_times[opid]] + [optim_values[opid]]\n",
    "    \n",
    "    print('Znalezione optimum:',\n",
    "          '\\n\\tLiczba sąsiadów:',founded_optim[0],\n",
    "          '\\n\\tMetryka:',founded_optim[1],\n",
    "          '\\n\\tStrategia:',founded_optim[2],\n",
    "          '\\n\\tDokładność:',founded_optim[3],'%',\n",
    "          '\\n\\tCzas weryfikacji:',founded_optim[4],'s'\n",
    "          '\\n\\tWartość optimum:',founded_optim[5],\n",
    "         )\n",
    "    \n",
    "    return founded_optim\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Znalezione optimum: \n",
      "\tLiczba sąsiadów: 3 \n",
      "\tMetryka: euclidean \n",
      "\tStrategia: OvR \n",
      "\tDokładność: 98.2861 % \n",
      "\tCzas weryfikacji: 1.1044 s\n",
      "\tWartość optimum: 0.9812044\n"
     ]
    }
   ],
   "source": [
    "#lista testowanych liczb sąsiadów (wedle uznania)\n",
    "neighbours = [3,5,7,9,11]\n",
    "\n",
    "#lista testowanych metryk (3)\n",
    "metrics = ['manhattan', 'euclidean', 'minkowski']\n",
    "\n",
    "#uruchomienie eksperymentu szukającego optymalnych wartości parametrów\n",
    "#czas wykonania może być długi, zależnie od podanej liczby sąsiadów i użytych metryk (NIE polecam 'minkowski' w strategii OvO)\n",
    "#jeśli jesteś gotowy przeprowadzić test całościowy, odkomentuj linijkę poniżej i poczekaj na wynik\n",
    "result_overall = runOverallExperiment(neighbours, metrics, 'dane_do_wykresow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Szukanie optymalnie zredukowanej przestrzeni cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funkcja przeprowadza eksperymenty dla danych z różnym stopniem redukcji przestrzeni cech\n",
    "#zapisuje dane wynikowe do pliku, zwraca najlepszy rezultat, a także wskazuje, jaki stopień redukcji jest prawdopodobnie najbardziej optymalny\n",
    "def runPCAExperiment(reducers, parameters, filename):\n",
    "\n",
    "    accurancies, veri_times = [],[]\n",
    "    \n",
    "    #wpisanie do pliku nagłówków kolumn\n",
    "    with open(filename + '.csv', 'w') as plik:\n",
    "        plik.write('przestrzen_cech;dokladnosc;czas_weryfikacji\\n')\n",
    "    \n",
    "    #wykonanie eksperymentów i uzupełnienie danych\n",
    "    for rc in reducers:\n",
    "        \n",
    "        #przygotowanie danych ze zredukowanym zestawem cech\n",
    "        reduced_X = reduceWithPCA(rc, X)\n",
    "        reduced_dataSet = prepareDataSet(reduced_X,y, random=False)\n",
    "        \n",
    "        result = runExperiment(reduced_dataSet, parameters[0], parameters[1], parameters[2])\n",
    "        \n",
    "        accurancies.append(result[0])\n",
    "        veri_times.append(result[1])\n",
    "        \n",
    "        with open(filename + '.csv', 'a') as plik:\n",
    "            plik.write(str(rc) + ';' + str(result[0]).replace('.',',') + ';' + str(result[1]).replace('.',',') + '\\n')\n",
    "    \n",
    "    #wyciąganie takich rezultatów, których dokładność jest nie mniejsza niż 1% optymalnego\n",
    "    candidates = [acc for acc in accurancies if acc >= result_overall[3]-1.]\n",
    "    \n",
    "    #szukanie najlepszego rezultatu\n",
    "    if(len(candidates) == 0):\n",
    "        gid = accurancies.index(max(accurancies))\n",
    "    else:\n",
    "        gid = accurancies.index(min(candidates))\n",
    "        \n",
    "    goal = [reducers[gid]] + [accurancies[gid]] + [veri_times[gid]]\n",
    "    \n",
    "    print('Optymalnie zredukowana przestrzeń:',\n",
    "          '\\n\\tWartość:',goal[0],\n",
    "          '\\n\\tDokładność:',goal[1],\n",
    "          '\\n\\tCzas weryfikacji:',goal[2],\n",
    "         )\n",
    "    return goal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optymalnie zredukowana przestrzeń: \n",
      "\tWartość: 11 \n",
      "\tDokładność: 97.2973 \n",
      "\tCzas weryfikacji: 0.525\n",
      "\n",
      "Końcowy wynik: \n",
      "\tZaoszczędzono: 0.5794 sekund \n",
      "\tKosztem: 0.9888 % dokładności\n"
     ]
    }
   ],
   "source": [
    "#lista przestrzeni do jakich będziemy redukować\n",
    "reducers = [16,15,14,13,12,11,10]\n",
    "\n",
    "#uruchomienie experymentu szukającego optymalnie zredukowanej przestrzeni cech\n",
    "result_final = runPCAExperiment(reducers, result_overall, 'dane_PCA')\n",
    "\n",
    "print('\\nKońcowy wynik:',\n",
    "      '\\n\\tZaoszczędzono:',round(result_overall[4] - result_final[2],4),'sekund',\n",
    "      '\\n\\tKosztem:',round(result_overall[3] - result_final[1],4),'% dokładności'\n",
    "     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
